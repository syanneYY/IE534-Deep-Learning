{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ADORABLE\\Software\\anaocnda\\envs\\main\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "# def load_data(filename):\n",
    "#load MNIST data\n",
    "MNIST_data = h5py.File(r'C:\\Users\\yshcc\\Desktop\\hw\\IE534DL\\hw1\\MNISTdata.hdf5', 'r')\n",
    "x_train = np.float32(MNIST_data['x_train'][:])\n",
    "y_train = np.int32(np.array(MNIST_data['y_train'][:,0]))\n",
    "x_test = np.float32( MNIST_data['x_test'][:] )\n",
    "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
    "MNIST_data.close()\n",
    "\n",
    "def normalization(x):\n",
    "    x_mean = x.mean(axis = 0)\n",
    "    x_std = x.std(axis = 0)\n",
    "    x_train = (x - x_mean)/x_std\n",
    "    return x\n",
    "x_train = normalization(x_train)\n",
    "x_test = normalization(x_test)\n",
    "\n",
    "def convert_to_onehot(Y, C): \n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "y_train = convert_to_onehot(y_train, 10)\n",
    "y_test = convert_to_onehot(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_par(n_input, n_hidden, n_output):\n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    parameters[\"W1\"] = np.random.randn(n_hidden, n_input) / np.sqrt(n_input)   # weight matrix\n",
    "    parameters[\"b1\"] = np.zeros(n_hidden)                 # bias vector\n",
    "    parameters[\"W2\"] = np.random.randn(n_output, n_hidden) / np.sqrt(n_hidden)\n",
    "    parameters[\"b2\"] = np.zeros(n_output)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, params):\n",
    "    cache = {}\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
    "    cache[\"H\"] = sigmoid(cache[\"Z1\"])\n",
    "#     print(\"H.shape\",cache[\"H\"].shape )\n",
    "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"H\"]) + params[\"b2\"]\n",
    "    cache[\"F\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
    "    return cache\n",
    "\n",
    "\n",
    "def back_propagation(X, Y, params, cache):\n",
    "    grads = {}\n",
    "#     print(\"Y\", Y)\n",
    "#     print(\"Y.shape\",Y.shape)\n",
    "    dZ2 = cache[\"F\"] - Y\n",
    "    \n",
    "    grads[\"dW2\"] = np.matmul(dZ2[:,np.newaxis], cache[\"H\"][np.newaxis,:])\n",
    "    grads[\"db2\"] = dZ2\n",
    "    \n",
    "    dH = np.matmul(params[\"W2\"].T, dZ2)\n",
    "    dZ1 = dH * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
    "#     print(dZ1.shape)\n",
    "#     print(X.shape)\n",
    "    grads[\"dW1\"] = np.matmul(dZ1[:,np.newaxis], X[np.newaxis,:])\n",
    "    grads[\"db1\"] = dZ1\n",
    "\n",
    "    return grads\n",
    "\n",
    "def update_par(parameters, grads, lr):\n",
    "    for l in range(1,3):\n",
    "        parameters['W' + str(l)] -= lr*grads['dW'+str(l)]\n",
    "        parameters['b' + str(l)] -= lr*grads['db'+str(l)]\n",
    "    return parameters   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, parameters,LR = 0.1,  num_iterations = 5, print_cost = False):\n",
    "    for epochs in range(num_iterations):\n",
    "            #Learning rate schedule\n",
    "            if (epochs > 5):\n",
    "                LR = 0.001\n",
    "            if (epochs > 10):\n",
    "                LR = 0.0001\n",
    "            if (epochs > 15):\n",
    "                LR = 0.00001\n",
    "            total_correct = 0\n",
    "            print(LR)\n",
    "            for n in range(len(x_train)):\n",
    "                n_random = randint(0,len(x_train)-1 )\n",
    "                y = y_train[n_random]\n",
    "                x = x_train[n_random][:]    \n",
    "                # forward\n",
    "                cache = forward(x, parameters)\n",
    "                # backward\n",
    "                grads = back_propagation(x, y, parameters, cache)\n",
    "                parameters = update_par(parameters, grads, LR)\n",
    "\n",
    "#                 W1 = parameters[\"W1\"]\n",
    "#                 b1 = parameters[\"b1\"]\n",
    "#                 W2 = parameters[\"W2\"]\n",
    "#                 b2 = parameters[\"b2\"]\n",
    "                \n",
    "                prediction = np.argmax(cache[\"F\"].T)\n",
    "                yy = np.argmax(y.T)\n",
    "                if (prediction == yy):\n",
    "                    total_correct += 1\n",
    "            print(total_correct)\n",
    "            print(total_correct/np.float(len(x_train)))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "56129\n",
      "0.9354833333333333\n",
      "0.1\n",
      "58224\n",
      "0.9704\n",
      "0.1\n",
      "58693\n",
      "0.9782166666666666\n",
      "0.1\n",
      "58937\n",
      "0.9822833333333333\n",
      "0.1\n",
      "59125\n",
      "0.9854166666666667\n"
     ]
    }
   ],
   "source": [
    "layers_dims = (784, 120, 10)\n",
    "parameters = initial_par(784, 120, 10)\n",
    "par = model(x_train, y_train, parameters,LR = 0.1,num_iterations = 5, print_cost = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9805\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "for n in range(len(x_test)):\n",
    "    y = y_test[n]\n",
    "    x = x_test[n][:]\n",
    "    cache = forward(x, par)\n",
    "    prediction = np.argmax(cache[\"F\"].T)\n",
    "    yy = np.argmax(y.T)\n",
    "    if (prediction == yy):\n",
    "        total_correct += 1\n",
    "print(total_correct/np.float(len(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
